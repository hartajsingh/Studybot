



	
	

	
	

	Minimax

	
		From Wikipedia, the free encyclopedia

		

		

		
		

		Jump to navigation
		Jump to search
		Decision rule used for minimizing the possible loss for a worst case scenario

This article is about the decision theory concept. For other uses, see Minimax (disambiguation).

Minimax (sometimes MinMax, MM[1] or saddle point[2]) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario.  When dealing with gains, it is referred to as "maximin"—to maximize the minimum gain.  Originally formulated for n-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.


Contents


	1 Game theory
	1.1 In general games
	1.2 In zero-sum games
	1.3 Example
	1.4 Maximin
	1.5 In repeated games



	2 Combinatorial game theory
	2.1 Minimax algorithm with alternate moves
	2.2 Pseudocode
	2.3 Example



	3 Minimax for individual decisions
	3.1 Minimax in the face of uncertainty
	3.2 Minimax criterion in statistical decision theory
	3.3 Non-probabilistic decision theory



	4 Maximin in philosophy
	5 See also
	6 Notes
	7 External links





Game theory[edit]

In general games[edit]

The maximin value is the highest value that the player can be sure to get without knowing the actions of the other players; equivalently, it is the lowest value the other players can force the player to receive when they know the player's action. Its formal definition is:[3]


	
  
    
      
        
          
            
              v
              
                i
              
            
            _
          
        
        =
        
          max
          
            
              a
              
                i
              
            
          
        
        
          min
          
            
              a
              
                −
                i
              
            
          
        
        
          
            v
            
              i
            
          
          (
          
            a
            
              i
            
          
          ,
          
            a
            
              −
              i
            
          
          )
        
      
    
    {\displaystyle {\underline {v_{i}}}=\max _{a_{i}}\min _{a_{-i}}{v_{i}(a_{i},a_{-i})}}
  



Where:


	i is the index of the player of interest.
	
  
    
      
        −
        i
      
    
    {\displaystyle -i}
  
 denotes all other players except player i.
	
  
    
      
        
          a
          
            i
          
        
      
    
    {\displaystyle a_{i}}
  
 is the action taken by player i.
	
  
    
      
        
          a
          
            −
            i
          
        
      
    
    {\displaystyle a_{-i}}
  
 denotes the actions taken by all other players.
	
  
    
      
        
          v
          
            i
          
        
      
    
    {\displaystyle v_{i}}
  
 is the value function of player i.


Calculating the maximin value of a player is done in a worst-case approach: for each possible action of the player, we check all possible actions of the other players and determine the worst possible combination of actions—the one that gives player i the smallest value. Then, we determine which action player i can take in order to make sure that this smallest value is the highest possible.

For example, consider the following game for two players, where the first player ("row player") may choose any of three moves, labelled T, M, or B, and the second player ("column" player) may choose either of two moves, L or R. The result of the combination of both moves is expressed in a payoff table:


		L	R

	T	3,1	2,-20

	M	5,0	-10,1

	B	-100,2	4,4



(where the first number in each cell is the pay-out of the row player and the second number is the pay-out of the column player).

For the sake of example, we consider only pure strategies. Check each player in turn:


	The row player can play T, which guarantees them a payoff of at least 2 (playing B is risky since it can lead to payoff −100, and playing M can result in a payoff of −10). Hence: 
  
    
      
        
          
            
              v
              
                r
                o
                w
              
            
            _
          
        
        =
        2
      
    
    {\displaystyle {\underline {v_{row}}}=2}
  
.
	The column player can play L and secure a payoff of at least 0 (playing R puts them in the risk of getting 
  
    
      
        −
        20
      
    
    {\displaystyle -20}
  
). Hence: 
  
    
      
        
          
            
              v
              
                c
                o
                l
              
            
            _
          
        
        =
        0
      
    
    {\displaystyle {\underline {v_{col}}}=0}
  
.


If both players play their respective maximin strategies 
  
    
      
        (
        T
        ,
        L
        )
      
    
    {\displaystyle (T,L)}
  
, the payoff vector is 
  
    
      
        (
        3
        ,
        1
        )
      
    
    {\displaystyle (3,1)}
  
.

The minimax value of a player is the smallest value that the other players can force the player to receive, without knowing the player's actions; equivalently, it is the largest value the player can be sure to get when they know the actions of the other players. Its formal definition is:[3]


	
  
    
      
        
          
            
              v
              
                i
              
            
            ¯
          
        
        =
        
          min
          
            
              a
              
                −
                i
              
            
          
        
        
          max
          
            
              a
              
                i
              
            
          
        
        
          
            v
            
              i
            
          
          (
          
            a
            
              i
            
          
          ,
          
            a
            
              −
              i
            
          
          )
        
      
    
    {\displaystyle {\overline {v_{i}}}=\min _{a_{-i}}\max _{a_{i}}{v_{i}(a_{i},a_{-i})}}
  



The definition is very similar to that of the maximin value—only the order of the maximum and minimum operators is inverse. In the above example:


	The row player can get a maximum value of 4 (if the other player plays R) or 5 (if the other player plays L), so: 
  
    
      
        
          
            
              v
              
                r
                o
                w
              
            
            ¯
          
        
        =
        4
      
    
    {\displaystyle {\overline {v_{row}}}=4}
  
.
	The column player can get a maximum value of 1 (if the other player plays T), 1 (if M) or 4 (if B). Hence: 
  
    
      
        
          
            
              v
              
                c
                o
                l
              
            
            ¯
          
        
        =
        1
      
    
    {\displaystyle {\overline {v_{col}}}=1}
  
.


For every player i, the maximin is at most the minimax:


	
  
    
      
        
          
            
              v
              
                i
              
            
            _
          
        
        ≤
        
          
            
              v
              
                i
              
            
            ¯
          
        
      
    
    {\displaystyle {\underline {v_{i}}}\leq {\overline {v_{i}}}}
  



Intuitively, in maximin the maximization comes before the minimization, so player i tries to maximize their value before knowing what the others will do; in minimax the maximization comes after the minimization, so player i is in a much better position—they maximize their value knowing what the others did.

Another way to understand the notation is by reading from right to left: when we write


	
  
    
      
        
          
            
              v
              
                i
              
            
            ¯
          
        
        =
        
          min
          
            
              a
              
                −
                i
              
            
          
        
        
          max
          
            
              a
              
                i
              
            
          
        
        
          
            v
            
              i
            
          
          (
          
            a
            
              i
            
          
          ,
          
            a
            
              −
              i
            
          
          )
        
        =
        
          min
          
            
              a
              
                −
                i
              
            
          
        
        
          
            (
          
        
        
          max
          
            
              a
              
                i
              
            
          
        
        
          
            v
            
              i
            
          
          (
          
            a
            
              i
            
          
          ,
          
            a
            
              −
              i
            
          
          )
        
        
          
            )
          
        
      
    
    {\displaystyle {\overline {v_{i}}}=\min _{a_{-i}}\max _{a_{i}}{v_{i}(a_{i},a_{-i})}=\min _{a_{-i}}{\Big (}\max _{a_{i}}{v_{i}(a_{i},a_{-i})}{\Big )}}
  



the initial set of outcomes 
  
    
      
        
          v
          
            i
          
        
        (
        
          a
          
            i
          
        
        ,
        
          a
          
            −
            i
          
        
        )
      
    
    {\displaystyle v_{i}(a_{i},a_{-i})}
  
 depends on both 
  
    
      
        
          
            a
            
              i
            
          
        
      
    
    {\displaystyle {a_{i}}}
  
 and 
  
    
      
        
          
            a
            
              −
              i
            
          
        
      
    
    {\displaystyle {a_{-i}}}
  
.  We first marginalize away 
  
    
      
        
          
            a
            
              i
            
          
        
      
    
    {\displaystyle {a_{i}}}
  
 from 
  
    
      
        
          v
          
            i
          
        
        (
        
          a
          
            i
          
        
        ,
        
          a
          
            −
            i
          
        
        )
      
    
    {\displaystyle v_{i}(a_{i},a_{-i})}
  
, by maximizing over 
  
    
      
        
          
            a
            
              i
            
          
        
      
    
    {\displaystyle {a_{i}}}
  
 (for every possible value of 
  
    
      
        
          
            a
            
              −
              i
            
          
        
      
    
    {\displaystyle {a_{-i}}}
  
) to yield a set of marginal outcomes 
  
    
      
        
          v
          
            i
          
          ′
        
        (
        
          a
          
            −
            i
          
        
        )
      
    
    {\displaystyle v'_{i}(a_{-i})}
  
, which depends only on 
  
    
      
        
          
            a
            
              −
              i
            
          
        
      
    
    {\displaystyle {a_{-i}}}
  
.  We then minimize over 
  
    
      
        
          
            a
            
              −
              i
            
          
        
      
    
    {\displaystyle {a_{-i}}}
  
 over these outcomes.  (Conversely for maximin.)

Although it is always the case that 
  
    
      
        
          
            
              v
              
                r
                o
                w
              
            
            _
          
        
        ≤
        
          
            
              v
              
                r
                o
                w
              
            
            ¯
          
        
      
    
    {\displaystyle {\underline {v_{row}}}\leq {\overline {v_{row}}}}
  
 and 
  
    
      
        
          
            
              v
              
                c
                o
                l
              
            
            _
          
        
        ≤
        
          
            
              v
              
                c
                o
                l
              
            
            ¯
          
        
      
    
    {\displaystyle {\underline {v_{col}}}\leq {\overline {v_{col}}}}
  
, the payoff vector resulting from both players playing their minimax strategies, 
  
    
      
        (
        2
        ,
        −
        20
        )
      
    
    {\displaystyle (2,-20)}
  
 in the case of 
  
    
      
        (
        T
        ,
        R
        )
      
    
    {\displaystyle (T,R)}
  
 or 
  
    
      
        (
        −
        10
        ,
        1
        )
      
    
    {\displaystyle (-10,1)}
  
 in the case of 
  
    
      
        (
        M
        ,
        R
        )
      
    
    {\displaystyle (M,R)}
  
, cannot similarly be ranked against the payoff vector 
  
    
      
        (
        3
        ,
        1
        )
      
    
    {\displaystyle (3,1)}
  
 resulting from both players playing their maximin strategy.


In zero-sum games[edit]


In two-player zero-sum games, the minimax solution is the same as the Nash equilibrium.

In the context of zero-sum games, the minimax theorem is equivalent to:[4][failed verification]


For every two-person, zero-sum game with finitely many strategies, there exists a value V and a mixed strategy for each player, such that

	(a) Given player 2's strategy, the best payoff possible for player 1 is V, and
	(b) Given player 1's strategy, the best payoff possible for player 2 is −V.




Equivalently, Player 1's strategy guarantees them a payoff of V regardless of Player 2's strategy, and similarly Player 2 can guarantee themselves a payoff of −V.  The name minimax arises because each player minimizes the maximum payoff possible for the other—since the game is zero-sum, they also minimize their own maximum loss (i.e. maximize their minimum payoff).
See also example of a game without a value.


Example[edit]

Payoff matrix for player A
	
	B chooses B1
	B chooses B2
	B chooses B3

	A chooses A1
	+3
	−2
	+2

	A chooses A2
	−1
	+0
	+4

	A chooses A3
	−4
	−3
	+1



The following example of a zero-sum game, where A and B make simultaneous moves, illustrates maximin solutions. Suppose each player has three choices and consider the payoff matrix for A displayed on the right. Assume the payoff matrix for B is the same matrix with the signs reversed (i.e. if the choices are A1 and B1 then B pays 3 to A). Then, the maximin choice for A is A2 since the worst possible result is then having to pay 1, while the simple maximin choice for B is B2 since the worst possible result is then no payment.  However, this solution is not stable, since if B believes A will choose A2 then B will choose B1 to gain 1; then if A believes B will choose B1 then A will choose A1 to gain 3; and then B will choose B2; and eventually both players will realize the difficulty of making a choice. So a more stable strategy is needed.

Some choices are dominated by others and can be eliminated: A will not choose A3 since either A1 or A2 will produce a better result, no matter what B chooses; B will not choose B3 since some mixtures of B1 and B2 will produce a better result, no matter what A chooses.

A can avoid having to make an expected payment of more than 1∕3 by choosing A1 with probability 1∕6 and A2 with probability 5∕6: The expected payoff for A would be 3 × (1∕6) − 1 × (5∕6) = −1∕3 in case B chose B1 and −2 × (1∕6) + 0 × (5∕6) = −1/3 in case B chose B2.  Similarly, B can ensure an expected gain of at least 1/3, no matter what A chooses, by using a randomized strategy of choosing B1 with probability 1∕3 and B2 with probability 2∕3. These mixed minimax strategies are now stable and cannot be improved.


Maximin[edit]

Frequently, in game theory, maximin is distinct from minimax. Minimax is used in zero-sum games to denote minimizing the opponent's maximum payoff. In a zero-sum game, this is identical to minimizing one's own maximum loss, and to maximizing one's own minimum gain.

"Maximin" is a term commonly used for non-zero-sum games to describe the strategy which maximizes one's own minimum payoff. In non-zero-sum games, this is not generally the same as minimizing the opponent's maximum gain, nor the same as the Nash equilibrium strategy.


In repeated games[edit]

The minimax values are very important in the theory of repeated games. One of the central theorems in this theory, the folk theorem, relies on the minimax values.


Combinatorial game theory[edit]

In combinatorial game theory, there is a minimax algorithm for game solutions.

A simple version of the minimax algorithm, stated below, deals with games such as tic-tac-toe, where each player can win, lose, or draw. If player A can win in one move, their best move is that winning move. If player B knows that one move will lead to the situation where player A can win in one move, while another move will lead to the situation where player A can, at best, draw, then player B's best move is the one leading to a draw. Late in the game, it's easy to see what the "best" move is. The Minimax algorithm helps find the best move, by working backwards from the end of the game. At each step it assumes that player A is trying to maximize the chances of A winning, while on the next turn player B is trying to minimize the chances of A winning (i.e., to maximize B's own chances of winning).


Minimax algorithm with alternate moves[edit]

A minimax algorithm[5] is a recursive algorithm for choosing the next move in an n-player game, usually a two-player game. A value is associated with each position or state of the game. This value is computed by means of a position evaluation function and it indicates how good it would be for a player to reach that position. The player then makes the move that maximizes the minimum value of the position resulting from the opponent's possible following moves. If it is A's turn to move, A gives a value to each of their legal moves.

A possible allocation method consists in assigning a certain win for A as +1 and for B as −1.  This leads to combinatorial game theory as developed by John Horton Conway. An alternative is using a rule that if the result of a move is an immediate win for A it is assigned positive infinity and if it is an immediate win for B, negative infinity. The value to A of any other move is the maximum of the values resulting from each of B's possible replies. For this reason, A is called the maximizing player and B is called the minimizing player, hence the name minimax algorithm. The above algorithm will assign a value of positive or negative infinity to any position since the value of every position will be the value of some final winning or losing position.  Often this is generally only possible at the very end of complicated games such as chess or go, since it is not computationally feasible to look ahead as far as the completion of the game, except towards the end, and instead, positions are given finite values as estimates of the degree of belief that they will lead to a win for one player or another.

This can be extended if we can supply a heuristic evaluation function which gives values to non-final game states without considering all possible following complete sequences. We can then limit the minimax algorithm to look only at a certain number of moves ahead. This number is called the "look-ahead", measured in "plies". For example, the chess computer Deep Blue (the first one to beat a reigning world champion, Garry Kasparov at that time) looked ahead at least 12 plies, then applied a heuristic evaluation function.[6]

The algorithm can be thought of as exploring the nodes of a game tree. The effective branching factor of the tree is the average number of children of each node (i.e., the average number of legal moves in a position).  The number of nodes to be explored usually increases exponentially with the number of plies (it is less than exponential if evaluating forced moves or repeated positions). The number of nodes to be explored for the analysis of a game is therefore approximately the branching factor raised to the power of the number of plies. It is therefore impractical to completely analyze games such as chess using the minimax algorithm.

The performance of the naïve minimax algorithm may be improved dramatically, without affecting the result, by the use of alpha–beta pruning. Other heuristic pruning methods can also be used, but not all of them are guaranteed to give the same result as the un-pruned search.

A naïve minimax algorithm may be trivially modified to additionally return an entire Principal Variation along with a minimax score.


Pseudocode[edit]

The pseudocode for the depth limited minimax algorithm is given below.


function minimax(node, depth, maximizingPlayer) is
    if depth = 0 or node is a terminal node then
        return the heuristic value of node
    if maximizingPlayer then
        value := −∞
        for each child of node do
            value := max(value, minimax(child, depth − 1, FALSE))
        return value
    else (* minimizing player *)
        value := +∞
        for each child of node do
            value := min(value, minimax(child, depth − 1, TRUE))
        return value


(* Initial call *)
minimax(origin, depth, TRUE)


The minimax function returns a heuristic value for leaf nodes (terminal nodes and nodes at the maximum search depth). Non-leaf nodes inherit their value from a descendant leaf node. The heuristic value is a score measuring the favorability of the node for the maximizing player. Hence nodes resulting in a favorable outcome, such as a win, for the maximizing player have higher scores than nodes more favorable for the minimizing player. The heuristic value for terminal (game ending) leaf nodes are scores corresponding to win, loss, or draw, for the maximizing player. For non terminal leaf nodes at the maximum search depth, an evaluation function estimates a heuristic value for the node. The quality of this estimate and the search depth determine the quality and accuracy of the final minimax result.

Minimax treats the two players (the maximizing player and the minimizing player) separately in its code. Based on the observation that 
  
    
      
        max
        (
        a
        ,
        b
        )
        =
        −
        min
        (
        −
        a
        ,
        −
        b
        )
      
    
    {\displaystyle \max(a,b)=-\min(-a,-b)}
  
, minimax may often be simplified into the negamax algorithm.


Example[edit]

  
A minimax tree example



  
An animated pedagogical example that attempts to be human-friendly by substituting initial infinite (or arbitrarily large) values for emptiness and by avoiding using the negamax coding simplifications.



Suppose the game being played only has a maximum of two possible moves per player each turn. The algorithm generates the tree on the right, where the circles represent the moves of the player running the algorithm (maximizing player), and squares represent the moves of the opponent (minimizing player). Because of the limitation of computation resources, as explained above, the tree is limited to a look-ahead of 4 moves.

The algorithm evaluates each leaf node using a heuristic evaluation function, obtaining the values shown. The moves where the maximizing player wins are assigned with positive infinity, while the moves that lead to a win of the minimizing player are assigned with negative infinity. At level 3, the algorithm will choose, for each node, the smallest of the child node values, and assign it to that same node (e.g. the node on the left will choose the minimum between "10" and "+∞", therefore assigning the value "10" to itself). The next step, in level 2, consists of choosing for each node the largest of the child node values. Once again, the values are assigned to each parent node. The algorithm continues evaluating the maximum and minimum values of the child nodes alternately until it reaches the root node, where it chooses the move with the largest value (represented in the figure with a blue arrow). This is the move that the player should make in order to minimize the maximum possible loss.


Minimax for individual decisions[edit]

Minimax in the face of uncertainty[edit]

Minimax theory has been extended to decisions where there is no other player, but where the consequences of decisions depend on unknown facts.  For example, deciding to prospect for minerals entails a cost which will be wasted if the minerals are not present, but will bring major rewards if they are.  One approach is to treat this as a game against nature (see move by nature), and using a similar mindset as Murphy's law or resistentialism, take an approach which minimizes the maximum expected loss, using the same techniques as in the two-person zero-sum games.

In addition, expectiminimax trees have been developed, for two-player games in which chance (for example, dice) is a factor.


Minimax criterion in statistical decision theory[edit]

Main article: Minimax estimator

In classical statistical decision theory, we have an estimator 
  
    
      
        δ
      
    
    {\displaystyle \delta }
  
 that is used to estimate a parameter 
  
    
      
        θ
        ∈
        Θ
      
    
    {\displaystyle \theta \in \Theta }
  
. We also assume a risk function 
  
    
      
        R
        (
        θ
        ,
        δ
        )
      
    
    {\displaystyle R(\theta ,\delta )}
  
, usually specified as the integral of a loss function. In this framework, 
  
    
      
        
          
            
              δ
              ~
            
          
        
      
    
    {\displaystyle {\tilde {\delta }}}
  
 is called minimax if it satisfies


	
  
    
      
        
          sup
          
            θ
          
        
        R
        (
        θ
        ,
        
          
            
              δ
              ~
            
          
        
        )
        =
        
          inf
          
            δ
          
        
        
          sup
          
            θ
          
        
        R
        (
        θ
        ,
        δ
        )
        .
      
    
    {\displaystyle \sup _{\theta }R(\theta ,{\tilde {\delta }})=\inf _{\delta }\sup _{\theta }R(\theta ,\delta ).}
  



An alternative criterion in the decision theoretic framework is the Bayes estimator in the presence of a prior distribution 
  
    
      
        Π
      
    
    {\displaystyle \Pi }
  
. An estimator is Bayes if it minimizes the average risk


	
  
    
      
        
          ∫
          
            Θ
          
        
        R
        (
        θ
        ,
        δ
        )
        
        d
        Π
        (
        θ
        )
        .
      
    
    {\displaystyle \int _{\Theta }R(\theta ,\delta )\,d\Pi (\theta ).}
  



Non-probabilistic decision theory[edit]

A key feature of minimax decision making is being non-probabilistic: in contrast to decisions using expected value or expected utility, it makes no assumptions about the probabilities of various outcomes, just scenario analysis of what the possible outcomes are. It is thus robust to changes in the assumptions, as these other decision techniques are not. Various extensions of this non-probabilistic approach exist, notably minimax regret and Info-gap decision theory.

Further, minimax only requires ordinal measurement (that outcomes be compared and ranked), not interval measurements (that outcomes include "how much better or worse"), and returns ordinal data, using only the modeled outcomes: the conclusion of a minimax analysis is: "this strategy is minimax, as the worst case is (outcome), which is less bad than any other strategy". Compare to expected value analysis, whose conclusion is of the form: "this strategy yields E(X)=n." Minimax thus can be used on ordinal data, and can be more transparent.


Maximin in philosophy[edit]

In philosophy, the term "maximin" is often used in the context of John Rawls's A Theory of Justice, where he refers to it (Rawls 1971, p. 152) in the context of The Difference Principle. Rawls defined this principle as the rule which states that social and economic inequalities should be arranged so that "they are to be of the greatest benefit to the least-advantaged members of society".[7][8]


See also[edit]

 
	Alpha–beta pruning
	Expectiminimax
	Negamax
	Sion's minimax theorem
	Minimax Condorcet
	Computer chess
	Horizon effect
	Monte Carlo tree search
	Minimax regret
	Negascout
	Tit for Tat
	Transposition table
	Wald's maximin model




Notes[edit]


	^ Provincial Healthcare Index 2013 (Bacchus Barua, Fraser Institute, January 2013 -see page 25-)

	^ Turing and von Neumann - Professor Raymond Flood - Gresham College at 12:00

	^ a b Michael Maschler, Eilon Solan & Shmuel Zamir (2013). Game Theory. Cambridge University Press. pp. 176–180. ISBN 9781107005488.CS1 maint: uses authors parameter (link)

	^ Osborne, Martin J., and Ariel Rubinstein. A Course in Game Theory. Cambridge, MA: MIT, 1994. Print.

	^ 
Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, pp. 163–171, ISBN 0-13-790395-2

	^ 
Hsu, Feng-Hsiung (1999), "IBM's Deep Blue Chess Grandmaster Chips", IEEE Micro, Los Alamitos, CA, USA: IEEE Computer Society, 19 (2): 70–81, doi:10.1109/40.755469, During the 1997 match, the software search extended the search to about 40 plies along the forcing lines, even though the nonextended search reached only about 12 plies.

	^ Arrow, "Some Ordinalist-Utilitarian Notes on Rawls's Theory of Justice, Journal of Philosophy 70, 9 (May 1973), pp. 245–263.

	^ Harsanyi, "Can the Maximin Principle Serve as a Basis for Morality? a Critique of John Rawls's Theory, American Political Science Review 69, 2 (June 1975), pp. 594-606.





External links[edit]

		Look up minimax in Wiktionary, the free dictionary.


		Wikiquote has quotations related to: Minimax


	
"Minimax principle", Encyclopedia of Mathematics, EMS Press, 2001 [1994]
	A visualization applet
	Maximin principle at Dictionary of Philosophical Terms and Names
	Play a betting-and-bluffing game against a mixed minimax strategy
	Minimax at Dictionary of Algorithms and Data Structures
	Minimax (with or without alpha-beta pruning) algorithm visualization — game tree solving (Java Applet), for balance or off-balance trees.
	Minimax Tutorial with a Numerical Solution Platform
	Java implementation used in a Checkers Game


		v
	t
	e


Topics in game theory

	Definitions	
	Congestion game
	Cooperative game
	Determinacy
	Escalation of commitment
	Extensive-form game
	First-player and second-player win
	Game complexity
	Game description language
	Graphical game
	Hierarchy of beliefs
	Information set
	Normal-form game
	Preference
	Sequential game
	Simultaneous game
	Simultaneous action selection
	Solved game
	Succinct game




	Equilibrium
concepts	
	Nash equilibrium
	Subgame perfection
	Mertens-stable equilibrium
	Bayesian Nash equilibrium
	Perfect Bayesian equilibrium
	Trembling hand
	Proper equilibrium
	Epsilon-equilibrium
	Correlated equilibrium
	Sequential equilibrium
	Quasi-perfect equilibrium
	Evolutionarily stable strategy
	Risk dominance
	 Core
	Shapley value
	Pareto efficiency
	Gibbs equilibrium
	Quantal response equilibrium
	Self-confirming equilibrium
	Strong Nash equilibrium
	Markov perfect equilibrium




	Strategies	
	Dominant strategies
	Pure strategy
	Mixed strategy
	Strategy-stealing argument
	Tit for tat
	Grim trigger
	Collusion
	Backward induction
	Forward induction
	Markov strategy
	Bid shading




	Classes
of games	
	Symmetric game
	Perfect information
	Repeated game
	Signaling game
	Screening game
	Cheap talk
	Zero-sum game
	Mechanism design
	Bargaining problem
	Stochastic game
	Mean-field game
	n-player game
	Large Poisson game
	Nontransitive game
	Global game
	Strictly determined game
	Potential game




	Games	
	Go
	Chess
	Infinite chess
	Checkers
	Tic-tac-toe
	Prisoner's dilemma
	Gift-exchange game
	Optional prisoner's dilemma
	Traveler's dilemma
	Coordination game
	Chicken
	Centipede game
	Lewis signaling game
	Volunteer's dilemma
	Dollar auction
	Battle of the sexes
	Stag hunt
	Matching pennies
	Ultimatum game
	Rock paper scissors
	Pirate game
	Dictator game
	Public goods game
	Blotto game
	War of attrition
	El Farol Bar problem
	Fair division
	Fair cake-cutting
	Cournot game
	Deadlock
	Diner's dilemma
	Guess 2/3 of the average
	Kuhn poker
	Nash bargaining game
	Induction puzzles
	Trust game
	Princess and monster game
	Rendezvous problem




	Theorems	
	Arrow's impossibility theorem
	Aumann's agreement theorem
	Folk theorem
	Minimax theorem
	Nash's theorem
	Purification theorem
	Revelation principle
	Zermelo's theorem




	Key
figures	
	Albert W. Tucker
	Amos Tversky
	Antoine Augustin Cournot
	Ariel Rubinstein
	Claude Shannon
	Daniel Kahneman
	David K. Levine
	David M. Kreps
	Donald B. Gillies
	Drew Fudenberg
	Eric Maskin
	Harold W. Kuhn
	Herbert Simon
	Hervé Moulin
	Jean Tirole
	Jean-François Mertens
	Jennifer Tour Chayes
	John Harsanyi
	John Maynard Smith
	John Nash
	John von Neumann
	Kenneth Arrow
	Kenneth Binmore
	Leonid Hurwicz
	Lloyd Shapley
	Melvin Dresher
	Merrill M. Flood
	Olga Bondareva
	Oskar Morgenstern
	Paul Milgrom
	Peyton Young
	Reinhard Selten
	Robert Axelrod
	Robert Aumann
	Robert B. Wilson
	Roger Myerson
	 Samuel Bowles
	Suzanne Scotchmer
	Thomas Schelling
	William Vickrey




	Miscellaneous	
	All-pay auction
	Alpha–beta pruning
	Bertrand paradox
	Bounded rationality
	Combinatorial game theory
	Confrontation analysis
	Coopetition
	Evolutionary game theory
	First-move advantage in chess
	Game mechanics
	Glossary of game theory
	List of game theorists
	List of games in game theory
	No-win situation
	Solving chess
	Topological game
	Tragedy of the commons
	Tyranny of small decisions






	
	v
	t
	e


Data structures and algorithms

	Data structures	
	Array
	Associative Array
	Binary Search Tree
	Fenwick Tree
	Graph
	Hash Table
	Heap
	Linked List
	Queue
	Segment Tree
	Stack
	String
	Tree
	Trie




	Algorithms	
	Backtracking
	Binary Search
	Breadth-First Search
	Depth-First Search
	Divide and Conquer
	Dynamic Programming
	Fold
	Greedy
	Minimax
	Recursion
	Sorting
	Streaming
	Sweep Line
	Topological Sorting














Retrieved from "https://en.wikipedia.org/w/index.php?title=Minimax&oldid=1007981344"


		Categories: 	Detection theory
	Game artificial intelligence
	Graph algorithms
	Optimization algorithms and methods
	Search algorithms
	Game theory
	Theorems in discrete mathematics
	Decision theory
	Fixed points (mathematics)


Hidden categories: 	CS1 maint: uses authors parameter
	Articles with short description
	Short description is different from Wikidata
	All articles with failed verification
	Articles with failed verification from February 2015
	Articles with example pseudocode




	




	





	Navigation menu

	
		

	
		Personal tools
	

	
			Not logged in
	Talk
	Contributions
	Create account
	Log in


		
	



		
			

	
		Namespaces
	

	
			Article
	Talk


		
	



			

	
	
		Variants
	

	
		

		
	



		

		
			

	
		Views
	

	
			Read
	Edit
	View history


		
	



			

	
	
		More
	

	
		

		
	



			
	
		Search
	

	
		
			
			
			
			
		

	




		

	

	

	
		
	

	

	
		Navigation
	

	
			Main page
	Contents
	Current events
	Random article
	About Wikipedia
	Contact us
	Donate


		
	



	

	
		Contribute
	

	
			Help
	Learn to edit
	Community portal
	Recent changes
	Upload file


		
	




	
		Tools
	

	
			What links here
	Related changes
	Upload file
	Special pages
	Permanent link
	Page information
	Cite this page
	Wikidata item


		
	




	
		Print/export
	

	
			Download as PDF
	Printable version


		
	



	

	
		Languages
	

	
			العربية
	Català
	Čeština
	Deutsch
	Español
	فارسی
	Français
	한국어
	Հայերեն
	Bahasa Indonesia
	Italiano
	עברית
	Jawa
	Magyar
	Nederlands
	日本語
	Polski
	Português
	Română
	Русский
	Slovenčina
	Српски / srpski
	ไทย
	Українська
	Tiếng Việt
	粵語
	中文


		Edit links

	









		 This page was last edited on 20 February 2021, at 23:10 (UTC).
	Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.



		Privacy policy
	About Wikipedia
	Disclaimers
	Contact Wikipedia
	Mobile view
	Developers
	Statistics
	Cookie statement



		
	









